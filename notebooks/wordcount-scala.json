{
  "paragraphs": [
    {
      "text": "%md\n## Welcome\nWelcome to Wizeline Data Engineering Academy! \n\nWe hope you have a great experience during the course and you end up with a solid grasp of the topics we'll be covering.\nIf you have any feedback about our courses, please feel free to send us an email to academy@wizeline.com.\n\n## Hello, World! -- Word Count (Scala Version)\nIn this exercise, your instructor will guide through the creation of an example program to count the number of words in a set of documents in Spark.\n\nAfterwards, you'll get a chance to complete a couple of exercises that extend that example and will help you solidify your understanding. \n\nPlease reach out to one of the tutors if you have any questions or run into trouble during the session.\n\nHave Fun!",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Welcome</h2>\n<p>Welcome to Wizeline Data Engineering Academy! </p>\n<p>We hope you have a great experience during the course and you end up with a solid grasp of the topics we&rsquo;ll be covering.<br/>If you have any feedback about our courses, please feel free to send us an email to <a href=\"mailto:&#97;c&#97;&#x64;&#x65;&#x6d;&#x79;&#64;&#x77;&#x69;z&#101;&#x6c;&#105;n&#101;&#46;&#99;o&#109;\">&#97;c&#97;&#x64;&#x65;&#x6d;&#x79;&#64;&#x77;&#x69;z&#101;&#x6c;&#105;n&#101;&#46;&#99;o&#109;</a>.</p>\n<h2>Hello, World! &ndash; Word Count (Scala Version)</h2>\n<p>In this exercise, your instructor will guide through the creation of an example program to count the number of words in a set of documents in Spark.</p>\n<p>Afterwards, you&rsquo;ll get a chance to complete a couple of exercises that extend that example and will help you solidify your understanding. </p>\n<p>Please reach out to one of the tutors if you have any questions or run into trouble during the session.</p>\n<p>Have Fun!</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969520_825111289",
      "id": "20180713-170034_521067052",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "focus": true,
      "$$hashKey": "object:30590"
    },
    {
      "text": "%md \n## Reading the dataset\nAs we mentioned before, we'll be using `Datasets` as our basic data structure, so let's import it:",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Reading the dataset</h2>\n<p>As we mentioned before, we&rsquo;ll be using <code>Datasets</code> as our basic data structure, so let&rsquo;s import it:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969521_824726540",
      "id": "20180713-152515_1970095947",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30591"
    },
    {
      "text": "import org.apache.spark.sql.Dataset",
      "user": "anonymous",
      "dateUpdated": "2018-08-02T22:01:33+0000",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql.Dataset\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969521_824726540",
      "id": "20180713-172417_1709710571",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "dateStarted": "2018-08-02T22:01:33+0000",
      "dateFinished": "2018-08-02T22:01:34+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30592"
    },
    {
      "text": "%md To begin our example, let's pull a text file from a public bucket in Google Cloud:",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>To begin our example, let&rsquo;s pull a text file from a public bucket in Google Cloud:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969521_824726540",
      "id": "20180713-172521_1303216552",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30593"
    },
    {
      "text": "def loadFile(bucket_file_path: String) = {\n    sc.textFile(bucket_file_path)\n}",
      "user": "anonymous",
      "dateUpdated": "2018-08-02T22:02:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "loadFile: (bucket_file_path: String)org.apache.spark.rdd.RDD[String]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969521_824726540",
      "id": "20180731-231058_192467631",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "dateStarted": "2018-08-02T22:02:12+0000",
      "dateFinished": "2018-08-02T22:02:12+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30594"
    },
    {
      "text": "val documents = loadFile(\"gs://de-training-input-bucket/words/big.txt\").toDS()\ndocuments.show()",
      "user": "anonymous",
      "dateUpdated": "2018-08-02T22:02:14+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "documents: org.apache.spark.sql.Dataset[String] = [value: string]\n+--------------------+\n|               value|\n+--------------------+\n|The Project Guten...|\n|by Sir Arthur Con...|\n|(#15 in our serie...|\n|                    |\n|Copyright laws ar...|\n|copyright laws fo...|\n|this or any other...|\n|                    |\n|This header shoul...|\n|Gutenberg file.  ...|\n|header without wr...|\n|                    |\n|Please read the \"...|\n|eBook and Project...|\n|important informa...|\n|how the file may ...|\n|donation to Proje...|\n|                    |\n|                    |\n|**Welcome To The ...|\n+--------------------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969521_824726540",
      "id": "20180713-152523_768975449",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "dateStarted": "2018-08-02T22:02:14+0000",
      "dateFinished": "2018-08-02T22:02:16+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30596"
    },
    {
      "text": "%md In this example, we will use only one document, but in practice you could extend this to use any number of documents in all sorts of formats, even if they couldn't fit in a single machine. That's the power of Spark!",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>In this example, we will use only one document, but in practice you could extend this to use any number of documents in all sorts of formats, even if they couldn&rsquo;t fit in a single machine. That&rsquo;s the power of Spark!</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969521_824726540",
      "id": "20180713-173145_1979252085",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30597"
    },
    {
      "text": "%md\n## Converting documents to words\nThough it's not completely necessary to define a separate function to break the input documents into words, we'll define a function `toWords` that will come in handy to have it once we get to other exercises to avoid duplicating code.\n\nThe function allows you to customize the boundaries between words using a regular expression. By default, it uses whitespaces as the delimiter. It also removes any empty words (e.g. for the text `\"hello,,world\"` and a separator that includes whitespace and commas, it would produce `\"hello\"` and `\"world\"` only)",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Converting documents to words</h2>\n<p>Though it&rsquo;s not completely necessary to define a separate function to break the input documents into words, we&rsquo;ll define a function <code>toWords</code> that will come in handy to have it once we get to other exercises to avoid duplicating code.</p>\n<p>The function allows you to customize the boundaries between words using a regular expression. By default, it uses whitespaces as the delimiter. It also removes any empty words (e.g. for the text <code>&quot;hello,,world&quot;</code> and a separator that includes whitespace and commas, it would produce <code>&quot;hello&quot;</code> and <code>&quot;world&quot;</code> only)</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969522_825880787",
      "id": "20180713-185000_1281997520",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30598"
    },
    {
      "text": "def toWords(documents: Dataset[String], separatorsRegexp: String = \"\"\"\\s+\"\"\"): Dataset[String] = {\n    documents.flatMap(doc => doc.split(separatorsRegexp))\n        .map(word => word.toLowerCase)\n        .filter(word => !word.isEmpty)\n}",
      "user": "anonymous",
      "dateUpdated": "2018-08-02T22:02:26+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "toWords: (documents: org.apache.spark.sql.Dataset[String], separatorsRegexp: String)org.apache.spark.sql.Dataset[String]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969522_825880787",
      "id": "20180713-162106_300537953",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "dateStarted": "2018-08-02T22:02:26+0000",
      "dateFinished": "2018-08-02T22:02:27+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30599"
    },
    {
      "text": "val words = toWords(documents)\nwords.show()",
      "dateUpdated": "2018-08-02T22:02:32+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "words: org.apache.spark.sql.Dataset[String] = [value: string]\n+----------+\n|     value|\n+----------+\n|       the|\n|   project|\n| gutenberg|\n|     ebook|\n|        of|\n|       the|\n|adventures|\n|        of|\n|  sherlock|\n|    holmes|\n|        by|\n|       sir|\n|    arthur|\n|     conan|\n|     doyle|\n|      (#15|\n|        in|\n|       our|\n|    series|\n|        by|\n+----------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969522_825880787",
      "id": "20180802-113255_1998417436",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30600",
      "user": "anonymous",
      "dateFinished": "2018-08-02T22:02:33+0000",
      "dateStarted": "2018-08-02T22:02:32+0000"
    },
    {
      "text": "%md Given that we're mostly interested in words without punctuation in this example, we'll use a more specific regular expression. Don't worry too much about the details, though. If you're curious about how exactly it works, you can check this [post](https://stackoverflow.com/questions/30074109/removing-punctuation-marks-form-text-in-scala-spark)",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Given that we&rsquo;re mostly interested in words without punctuation in this example, we&rsquo;ll use a more specific regular expression. Don&rsquo;t worry too much about the details, though. If you&rsquo;re curious about how exactly it works, you can check this <a href=\"https://stackoverflow.com/questions/30074109/removing-punctuation-marks-form-text-in-scala-spark\">post</a></p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969522_825880787",
      "id": "20180713-193952_1952995095",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30601"
    },
    {
      "text": "val punctuationRegexp = \"\"\"[\\p{Punct}\\s]\"\"\"",
      "dateUpdated": "2018-08-02T22:02:37+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "punctuationRegexp: String = [\\p{Punct}\\s]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969522_825880787",
      "id": "20180713-194312_424075201",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30602",
      "user": "anonymous",
      "dateFinished": "2018-08-02T22:02:37+0000",
      "dateStarted": "2018-08-02T22:02:37+0000"
    },
    {
      "text": "%md Let's make sure that our function `toWords` produces the expected output (i.e. a set of words):",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Let&rsquo;s make sure that our function <code>toWords</code> produces the expected output (i.e. a set of words):</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969522_825880787",
      "id": "20180713-192314_2145515679",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30603"
    },
    {
      "text": "val words = toWords(documents)\nwords.show()",
      "dateUpdated": "2018-08-02T22:02:44+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "words: org.apache.spark.sql.Dataset[String] = [value: string]\n+----------+\n|     value|\n+----------+\n|       the|\n|   project|\n| gutenberg|\n|     ebook|\n|        of|\n|       the|\n|adventures|\n|        of|\n|  sherlock|\n|    holmes|\n|        by|\n|       sir|\n|    arthur|\n|     conan|\n|     doyle|\n|      (#15|\n|        in|\n|       our|\n|    series|\n|        by|\n+----------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969522_825880787",
      "id": "20180713-192337_1741363054",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30604",
      "user": "anonymous",
      "dateFinished": "2018-08-02T22:02:45+0000",
      "dateStarted": "2018-08-02T22:02:44+0000"
    },
    {
      "text": "%md\n### Incremental Development and Exploration\nThough it's convenient to have a function to reuse, when we're developing code for the first time it's usually a good idea to try individual function calls in isolation to make sure the data is flowing as expected.\n\nLet's go ahead and try a couple of those functions in isolation:",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Incremental Development and Exploration</h3>\n<p>Though it&rsquo;s convenient to have a function to reuse, when we&rsquo;re developing code for the first time it&rsquo;s usually a good idea to try individual function calls in isolation to make sure the data is flowing as expected.</p>\n<p>Let&rsquo;s go ahead and try a couple of those functions in isolation:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969522_825880787",
      "id": "20180713-190730_1897522264",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30605"
    },
    {
      "text": "val lowerCasedDocs = documents.map(doc => doc.toLowerCase)\nlowerCasedDocs.show()",
      "dateUpdated": "2018-08-02T22:02:48+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "lowerCasedDocs: org.apache.spark.sql.Dataset[String] = [value: string]\n+--------------------+\n|               value|\n+--------------------+\n|the project guten...|\n|by sir arthur con...|\n|(#15 in our serie...|\n|                    |\n|copyright laws ar...|\n|copyright laws fo...|\n|this or any other...|\n|                    |\n|this header shoul...|\n|gutenberg file.  ...|\n|header without wr...|\n|                    |\n|please read the \"...|\n|ebook and project...|\n|important informa...|\n|how the file may ...|\n|donation to proje...|\n|                    |\n|                    |\n|**welcome to the ...|\n+--------------------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969522_825880787",
      "id": "20180713-191055_175413413",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30606",
      "user": "anonymous",
      "dateFinished": "2018-08-02T22:02:49+0000",
      "dateStarted": "2018-08-02T22:02:48+0000"
    },
    {
      "text": "val filteredWords = (documents\n    .flatMap(doc => doc.split(punctuationRegexp))\n    .filter(word => word.size > 0 && word.size < 5))\n\nfilteredWords.show()",
      "dateUpdated": "2018-08-02T22:02:53+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "filteredWords: org.apache.spark.sql.Dataset[String] = [value: string]\n+-----+\n|value|\n+-----+\n|  The|\n|   of|\n|  The|\n|   of|\n|   by|\n|  Sir|\n|   15|\n|   in|\n|  our|\n|   by|\n|  Sir|\n| laws|\n|  are|\n|  all|\n| over|\n|  the|\n|   Be|\n| sure|\n|   to|\n|  the|\n+-----+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969523_825496038",
      "id": "20180713-191334_296049631",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30607",
      "user": "anonymous",
      "dateFinished": "2018-08-02T22:02:55+0000",
      "dateStarted": "2018-08-02T22:02:53+0000"
    },
    {
      "text": "%md\nFeel free to try and experiment with all sorts of expressions until you feel comfortable with your understanding of how the data is being transformed and flowing from function to function.",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Feel free to try and experiment with all sorts of expressions until you feel comfortable with your understanding of how the data is being transformed and flowing from function to function.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969523_825496038",
      "id": "20180713-191737_182562044",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30608"
    },
    {
      "text": "%md\n## Counting Words\nLet's now move on to solving the problem we started with! With the `toWords` function in our hands, our `countWords` function should be pretty short:",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Counting Words</h2>\n<p>Let&rsquo;s now move on to solving the problem we started with! With the <code>toWords</code> function in our hands, our <code>countWords</code> function should be pretty short:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969523_825496038",
      "id": "20180713-192012_688996853",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30609"
    },
    {
      "text": "def countWords(documents: Dataset[String], separatorsRegexp: String = \"\"\"\\s+\"\"\") : Dataset[(String, Long)] = {\n    val words = toWords(documents, separatorsRegexp)\n    val counts = words.groupByKey(identity).count()\n    counts\n}",
      "dateUpdated": "2018-08-02T22:02:58+0000",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "countWords: (documents: org.apache.spark.sql.Dataset[String], separatorsRegexp: String)org.apache.spark.sql.Dataset[(String, Long)]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969523_825496038",
      "id": "20180713-165608_638775812",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30610",
      "user": "anonymous",
      "dateFinished": "2018-08-02T22:02:59+0000",
      "dateStarted": "2018-08-02T22:02:58+0000"
    },
    {
      "text": "%md Let's test it (if you need a refresher of what's going on with the `groupByKey` and `count` functions, please refer to the slides shown earlier in this session):",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Let&rsquo;s test it (if you need a refresher of what&rsquo;s going on with the <code>groupByKey</code> and <code>count</code> functions, please refer to the slides shown earlier in this session):</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969527_823957042",
      "id": "20180713-192508_1130563054",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30611"
    },
    {
      "text": "val counts = countWords(words, punctuationRegexp)\ncounts.show()",
      "dateUpdated": "2018-08-02T22:03:04+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "counts: org.apache.spark.sql.Dataset[(String, Long)] = [value: string, count(1): bigint]\n+------------+--------+\n|       value|count(1)|\n+------------+--------+\n|       still|     922|\n|       those|    1201|\n|        some|    1536|\n|         few|     458|\n|      doubts|      39|\n|       inner|      60|\n|        hope|     149|\n|    everyday|      14|\n|   connected|      52|\n| requirement|       3|\n|     flashed|      17|\n|      travel|      29|\n|  concluding|       3|\n|         fog|      23|\n|      spared|      12|\n|         art|      47|\n|accumulation|      25|\n|      waters|      30|\n|      poetry|      10|\n|    whishing|       1|\n+------------+--------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969527_823957042",
      "id": "20180713-165720_1184054894",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30612",
      "user": "anonymous",
      "dateFinished": "2018-08-02T22:03:08+0000",
      "dateStarted": "2018-08-02T22:03:04+0000"
    },
    {
      "text": "%md It works! Yay!",
      "dateUpdated": "2018-08-02T21:06:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>It works! Yay!</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533243969527_823957042",
      "id": "20180713-194553_145958858",
      "dateCreated": "2018-08-02T21:06:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:30613"
    }
  ],
  "name": "wordcount-scala.json",
  "id": "2DNG2M2H7",
  "angularObjects": {
    "2DMMG5R5U:shared_process": [],
    "2DMT86YGX:shared_process": [],
    "2DPWEQ61Y:shared_process": [],
    "2DMEHY72N:shared_process": [],
    "2DM7364MX:shared_process": [],
    "2DNAV2RDZ:shared_process": [],
    "2DKPGN4BS:shared_process": [],
    "2DM57QEWS:shared_process": [],
    "2DNX77NXA:shared_process": [],
    "2DPMYPEZB:shared_process": [],
    "2DKSKB5FX:shared_process": [],
    "2DN3AXQ6J:shared_process": [],
    "2DK2ZKHE6:shared_process": [],
    "2DPW1ZPP3:shared_process": [],
    "2DPJJPUEP:shared_process": [],
    "2DN7VDD8E:shared_process": [],
    "2DP583F4B:shared_process": [],
    "2DN7TAJ65:shared_process": []
  },
  "config": {
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}