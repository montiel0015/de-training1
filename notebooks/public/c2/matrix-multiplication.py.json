{
   "paragraphs": [
      {
         "text": "%md\n# Iterations and matrix multiplication\n\nWelcome to the notebook with the asasignment for the second session. You\u2019re well on your way to obtain the Wizeline Certification for Big Data Engineering with Spark!\n\nIf you have any feedback about our courses, email us at academy@wizeline.com or use the Academy Slack channel.",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "tableHide": false,
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            },
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<h1>Iterations and matrix multiplication</h1>\n<p>Welcome to the notebook with the asasignment for the second session. You\u2019re well on your way to obtain the Wizeline Certification for Big Data Engineering with Spark!</p>\n<p>If you have any feedback about our courses, email us at <a href=\"mailto:&#x61;&#99;&#97;&#100;&#101;&#x6d;&#121;&#64;&#119;&#x69;&#122;&#101;&#x6c;&#105;&#x6e;&#x65;&#x2e;&#x63;&#111;&#x6d;\">&#x61;&#99;&#97;&#100;&#101;&#x6d;&#121;&#64;&#119;&#x69;&#122;&#101;&#x6c;&#105;&#x6e;&#x65;&#x2e;&#x63;&#111;&#x6d;</a> or use the Academy Slack channel.</p>\n</div>"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387179_1165562518",
         "id": "20180815-184319_767984790",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "focus": true,
         "$$hashKey": "object:490"
      },
      {
         "text": "%md\n## Matrix Multiplication Assignment\n\nIn this exercise, you will be implementing a Matrix multiplication on a larger dataset than the one you\u2019ve used so far. \n\nYou will be challenged to work with two DataFrames, transform them into `CoordinateMatrix` objects, and ultimately convert each to a `BlockMatrix`.",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "tableHide": false,
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            },
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<h2>Matrix Multiplication Assignment</h2>\n<p>In this exercise, you will be implementing a Matrix multiplication on a larger dataset than the one you\u2019ve used so far. </p>\n<p>You will be challenged to work with two DataFrames, transform them into <code>CoordinateMatrix</code> objects, and ultimately convert each to a <code>BlockMatrix</code>.</p>\n</div>"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387180_1163638773",
         "id": "20180816-044039_285868597",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:491"
      },
      {
         "text": "%md\n\n```\nFile Format:\nEach line in the text file is a row in the matrix. They are comma-separated values. The first value is the row index starting at one, the remaining are the Matrix values. \n```\n\nFirst, import the libraries to use during the session with the following command:\n\n",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "tableHide": false,
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            },
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<pre><code>File Format:\nEach line in the text file is a row in the matrix. They are comma-separated values. The first value is the row index starting at one, the remaining are the Matrix values. \n</code></pre>\n<p>First, import the libraries to use during the session with the following command:</p>\n</div>"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387181_1163254024",
         "id": "20180816-050807_2103207409",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:492"
      },
      {
         "text": "%pyspark\nfrom pyspark.sql.functions import array, posexplode\nfrom pyspark.mllib.linalg.distributed import CoordinateMatrix, BlockMatrix\n",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "tableHide": true,
            "editorSetting": {
               "language": "python",
               "editOnDblClick": false
            },
            "colWidth": 12,
            "editorMode": "ace/mode/python",
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": []
         },
         "apps": [],
         "jobName": "paragraph_1534456387181_1163254024",
         "id": "20180816-051038_545285622",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:493"
      },
      {
         "text": "%md\nNext, use `spark.read.csv` to read the two matrices (`matrix1.txt` and `matrix2.txt`) on the bucket URI: \n`gs://de-training-input/matrices/matrix*.txt`\n\nBecause there are two matrices, make a read call for each and store them in separate variables `m1s` and `m2s`. \n\nThe function already takes into account the commas. No need to map a split by \u201c,\u201d while reading the files. The objects will already be DataFrames.\n\n",
         "dateUpdated": "2018-08-16T22:05:46+0000",
         "config": {
            "tableHide": false,
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            },
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "apps": [],
         "jobName": "paragraph_1534456387181_1163254024",
         "id": "20180816-051039_1898536718",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "FINISHED",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:494",
         "user": "anonymous",
         "dateFinished": "2018-08-16T22:05:46+0000",
         "dateStarted": "2018-08-16T22:05:46+0000",
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<p>Next, use <code>spark.read.csv</code> to read the two matrices (<code>matrix1.txt</code> and <code>matrix2.txt</code>) on the bucket URI:<br/><code>gs://de-training-input/matrices/matrix*.txt</code></p>\n<p>Because there are two matrices, make a read call for each and store them in separate variables <code>m1s</code> and <code>m2s</code>. </p>\n<p>The function already takes into account the commas. No need to map a split by \u201c,\u201d while reading the files. The objects will already be DataFrames.</p>\n</div>"
               }
            ]
         }
      },
      {
         "text": "%pyspark\n\n",
         "dateUpdated": "2018-08-16T22:05:50+0000",
         "config": {
            "colWidth": 12,
            "editorMode": "ace/mode/python",
            "results": {},
            "enabled": true,
            "editorSetting": {
               "language": "python",
               "editOnDblClick": false
            }
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": []
         },
         "apps": [],
         "jobName": "paragraph_1534456387181_1163254024",
         "id": "20180816-070420_1766932377",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:495"
      },
      {
         "text": "%md\nUnlike the Scala version, in PySpark we\u2019ll use Tuples and DataFrames to work with the data.\n\n**Transform to tuples**\nNow that we have loaded the data into Spark as DataFrames, we need to transform them into Tuples. The code pieces you will require to do this are:\n* **.columns**: DataFrame attribute to manipulate its columns. It outputs a List of values. You can slice it similarly to a Python list.\n* **array()**: Receives a List of values to convert it into an array.\n* **posexplode()**: Transposes an array and adds the index position to the left. Output is two columns.\n* **.select()**: DataFrame method to extract or define new columns of data.\n\nStore the output of the final select in a variable for each Matrix.\n\n**HINT:** `_c0` can be used to reference the first column in the object read by `spark.read.csv` if no names were provided inside the file.\n",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "tableHide": false,
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            },
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<p>Unlike the Scala version, in PySpark we\u2019ll use Tuples and DataFrames to work with the data.</p>\n<p><strong>Transform to tuples</strong><br/>Now that we have loaded the data into Spark as DataFrames, we need to transform them into Tuples. The code pieces you will require to do this are:<br/>* <strong>.columns</strong>: DataFrame attribute to manipulate its columns. It outputs a List of values. You can slice it similarly to a Python list.<br/>* <strong>array()</strong>: Receives a List of values to convert it into an array.<br/>* <strong>posexplode()</strong>: Transposes an array and adds the index position to the left. Output is two columns.<br/>* <strong>.select()</strong>: DataFrame method to extract or define new columns of data.</p>\n<p>Store the output of the final select in a variable for each Matrix.</p>\n<p><strong>HINT:</strong> <code>_c0</code> can be used to reference the first column in the object read by <code>spark.read.csv</code> if no names were provided inside the file.</p>\n</div>"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387182_1164408271",
         "id": "20180816-204921_95995530",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:496"
      },
      {
         "text": "%pyspark\n",
         "dateUpdated": "2018-08-16T22:05:53+0000",
         "config": {
            "colWidth": 12,
            "editorMode": "ace/mode/python",
            "results": {},
            "enabled": true,
            "editorSetting": {
               "language": "python",
               "editOnDblClick": false
            }
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": []
         },
         "apps": [],
         "jobName": "paragraph_1534456387182_1164408271",
         "id": "20180816-070426_2002522120",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:497"
      },
      {
         "text": "%md\nNow that we have converted all of our lines into coordinate `Tuples` (Triplets), we need to put them all inside a `BlockMatrix`. The function `create_blockMatrix`, defined in another notebook receives one of the previous objects and uses a `CoordinateMatrix` to output a `BlockMatrix`.",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "tableHide": false,
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            },
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<p>Now that we have converted all of our lines into coordinate <code>Tuples</code> (Triplets), we need to put them all inside a <code>BlockMatrix</code>. The function <code>create_blockMatrix</code>, defined in another notebook receives one of the previous objects and uses a <code>CoordinateMatrix</code> to output a <code>BlockMatrix</code>.</p>\n</div>"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387182_1164408271",
         "id": "20180816-205123_996053931",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:498"
      },
      {
         "text": "%pyspark\n",
         "dateUpdated": "2018-08-16T22:05:57+0000",
         "config": {
            "colWidth": 12,
            "editorMode": "ace/mode/python",
            "results": {},
            "enabled": true,
            "editorSetting": {
               "language": "python",
               "editOnDblClick": false
            }
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": []
         },
         "apps": [],
         "jobName": "paragraph_1534456387182_1164408271",
         "id": "20180816-051640_149771352",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:499"
      },
      {
         "text": "%md\nNow we convert each DataFrame into a `BlockMatrix`:",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "tableHide": false,
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            },
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<p>Now we convert each DataFrame into a <code>BlockMatrix</code>:</p>\n</div>"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387182_1164408271",
         "id": "20180816-051434_624669525",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:500"
      },
      {
         "text": "%pyspark\nblockM1 = create_blockMatrix(m1e)\nblockM2 = create_blockMatrix(m2e)",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "colWidth": 12,
            "editorMode": "ace/mode/python",
            "results": {},
            "enabled": true,
            "editorSetting": {
               "language": "python",
               "editOnDblClick": false
            }
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": []
         },
         "apps": [],
         "jobName": "paragraph_1534456387183_1164023522",
         "id": "20180816-053544_199438445",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:501"
      },
      {
         "text": "%md\nFinally, to perform the optimized multiplication use the `multiply` method of the `BlockMatrix`. As an exercise multiply `blockM1` against `blockM2`. Store the result in a variable.",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            },
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<p>Finally, to perform the optimized multiplication use the <code>multiply</code> method of the <code>BlockMatrix</code>. As an exercise multiply <code>blockM1</code> against <code>blockM2</code>. Store the result in a variable.</p>\n</div>"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387183_1164023522",
         "id": "20180816-053542_76914317",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:502"
      },
      {
         "text": "%pyspark\n",
         "dateUpdated": "2018-08-16T22:05:59+0000",
         "config": {
            "colWidth": 12,
            "editorMode": "ace/mode/python",
            "results": {},
            "enabled": true,
            "editorSetting": {
               "language": "python"
            }
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": []
         },
         "apps": [],
         "jobName": "paragraph_1534456387183_1164023522",
         "id": "20180816-054044_1121238451",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:503"
      },
      {
         "text": "%md\nOnce the computation is over, save the results to your output bucket. To do so, you will need to transform the `result` object into a `CoordinateMatrix`. Then pointing to its entries, use the `saveAsTextFile` method. Use the following GCS URI template:\n\n`gs://de-training-output-<yourusername>/assignment-1/`\n\nMake sure to replace `<user-name>` with your personal username ID.",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "tableHide": false,
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            },
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<p>Once the computation is over, save the results to your output bucket. To do so, you will need to transform the <code>result</code> object into a <code>CoordinateMatrix</code>. Then pointing to its entries, use the <code>saveAsTextFile</code> method. Use the following GCS URI template:</p>\n<p><code>gs://de-training-output-&lt;yourusername&gt;/assignment-1/</code></p>\n<p>Make sure to replace <code>&lt;user-name&gt;</code> with your personal username ID.</p>\n</div>"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387183_1164023522",
         "id": "20180816-205712_662995405",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:504"
      },
      {
         "text": "%pyspark\n",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "tableHide": true,
            "editorSetting": {
               "language": "python",
               "editOnDblClick": false
            },
            "colWidth": 12,
            "editorMode": "ace/mode/python",
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "ERROR",
            "msg": [
               {
                  "type": "TEXT",
                  "data": "Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-2826862087346284577.py\", line 367, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-2826862087346284577.py\", line 360, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 1553, in saveAsTextFile\n    keyed._jrdd.map(self.ctx._jvm.BytesToString()).saveAsTextFile(path)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 79, in deco\n    raise IllegalArgumentException(s.split(': ', 1)[1], stackTrace)\nIllegalArgumentException: u'Invalid bucket name (de-training-output-<user-name>) or object name ()'\n\n"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387184_1174411743",
         "id": "20180816-205739_1289702401",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:505"
      },
      {
         "text": "%md\n**Note:** we are converting the `BlockMatrix` back to `CoordinateMatrix` for writing purposes, the `BlockMatrix`.",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "editorSetting": {
               "language": "scala"
            },
            "colWidth": 12,
            "editorMode": "ace/mode/scala",
            "editorHide": true,
            "results": {},
            "enabled": true
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "results": {
            "code": "SUCCESS",
            "msg": [
               {
                  "type": "HTML",
                  "data": "<div class=\"markdown-body\">\n<p><strong>Note:</strong> we are converting the <code>BlockMatrix</code> back to <code>CoordinateMatrix</code> for writing purposes, the <code>BlockMatrix</code>.</p>\n</div>"
               }
            ]
         },
         "apps": [],
         "jobName": "paragraph_1534456387184_1174411743",
         "id": "20180816-055549_596649276",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:506"
      },
      {
         "text": "%md\n",
         "dateUpdated": "2018-08-16T21:53:07+0000",
         "config": {
            "colWidth": 12,
            "editorMode": "ace/mode/markdown",
            "results": {},
            "enabled": true,
            "editorSetting": {
               "language": "markdown",
               "editOnDblClick": true
            }
         },
         "settings": {
            "params": {},
            "forms": {}
         },
         "apps": [],
         "jobName": "paragraph_1534456387184_1174411743",
         "id": "20180816-061612_1285669371",
         "dateCreated": "2018-08-16T21:53:07+0000",
         "status": "READY",
         "errorMessage": "",
         "progressUpdateIntervalMs": 500,
         "$$hashKey": "object:507"
      }
   ],
   "name": "Matrix-Multiplication-Python",
   "id": "2DN27GG9N",
   "angularObjects": {
      "2DPV5GYZV:shared_process": [],
      "2DMXVEND8:shared_process": [],
      "2DP2JZ1T7:shared_process": [],
      "2DMQCTGAC:shared_process": [],
      "2DPT2WPZN:shared_process": [],
      "2DMAE54WY:shared_process": [],
      "2DMJQGHDP:shared_process": [],
      "2DQXFTHN6:shared_process": [],
      "2DNHU9QDY:shared_process": [],
      "2DPC2RS1N:shared_process": [],
      "2DMMWEW7N:shared_process": [],
      "2DNSBFHYA:shared_process": [],
      "2DPPW98XB:shared_process": [],
      "2DP8U9D6K:shared_process": [],
      "2DN67JH1V:shared_process": [],
      "2DNHYRTT8:shared_process": [],
      "2DMJY7M94:shared_process": [],
      "2DQQ5WYPM:shared_process": []
   },
   "config": {
      "looknfeel": "default",
      "personalizedMode": "false"
   },
   "info": {}
}
