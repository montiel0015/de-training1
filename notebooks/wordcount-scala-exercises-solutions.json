{
  "paragraphs": [
    {
      "text": "%md\n## \"Word Count\" Exercises Solutions (Scala)\n**IMPORTANT**: Remember that the best way to learn is by doing. So, if you haven't yet tried to complete the exercises on your own, give them a try before looking at the following solutions.\n\nWe'll begin by loading once again the documents for further processing and reusing the `toWords` and `countWords` functions that we saw during the session:",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:21.047",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>&ldquo;Word Count&rdquo; Exercises Solutions (Scala)</h2>\n<p><strong>IMPORTANT</strong>: Remember that the best way to learn is by doing. So, if you haven&rsquo;t yet tried to complete the exercises on your own, give them a try before looking at the following solutions.</p>\n<p>We&rsquo;ll begin by loading once again the documents for further processing and reusing the <code>toWords</code> and <code>countWords</code> functions that we saw during the session:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870826_-2109303975",
      "id": "20180717-203219_1843464497",
      "dateCreated": "2018-08-07 16:54:30.826",
      "dateStarted": "2018-08-07 19:51:21.065",
      "dateFinished": "2018-08-07 19:51:21.069",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.sql.Dataset\n\ndef toWords(documents: Dataset[String], separatorsRegexp: String = \"\"\"\\s+\"\"\"): Dataset[String] = {\n    documents.flatMap(doc => doc.split(separatorsRegexp))\n        .map(word => word.toLowerCase)\n        .filter(word => !word.isEmpty)\n}",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:21.164",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql.Dataset\ntoWords: (documents: org.apache.spark.sql.Dataset[String], separatorsRegexp: String)org.apache.spark.sql.Dataset[String]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870827_-1190362014",
      "id": "20180717-211731_1841768387",
      "dateCreated": "2018-08-07 16:54:30.827",
      "dateStarted": "2018-08-07 19:51:21.181",
      "dateFinished": "2018-08-07 19:51:22.099",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "def countWords(documents: Dataset[String], separatorsRegexp: String = \"\"\"\\s+\"\"\") : Dataset[(String, Long)] = {\n    val words = toWords(documents, separatorsRegexp)\n    val counts = words.groupByKey(identity).count()\n    counts\n}",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:22.107",
      "config": {
        "lineNumbers": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "countWords: (documents: org.apache.spark.sql.Dataset[String], separatorsRegexp: String)org.apache.spark.sql.Dataset[(String, Long)]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870827_1614851816",
      "id": "20180717-211745_1951066762",
      "dateCreated": "2018-08-07 16:54:30.827",
      "dateStarted": "2018-08-07 19:51:22.141",
      "dateFinished": "2018-08-07 19:51:22.554",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "def loadFile(bucket_file_path: String): Dataset[String] = {\n    spark.read.textFile(bucket_file_path)\n}",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:22.655",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "loadFile: (bucket_file_path: String)org.apache.spark.sql.Dataset[String]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870828_470588801",
      "id": "20180731-232114_598900552",
      "dateCreated": "2018-08-07 16:54:30.828",
      "dateStarted": "2018-08-07 19:51:22.669",
      "dateFinished": "2018-08-07 19:51:22.919",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val documents = loadFile(\"gs://de-training-input-bucket/words/big.txt\")\ndocuments.show()",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:22.974",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "documents: org.apache.spark.sql.Dataset[String] = [value: string]\n+--------------------+\n|               value|\n+--------------------+\n|The Project Guten...|\n|by Sir Arthur Con...|\n|(#15 in our serie...|\n|                    |\n|Copyright laws ar...|\n|copyright laws fo...|\n|this or any other...|\n|                    |\n|This header shoul...|\n|Gutenberg file.  ...|\n|header without wr...|\n|                    |\n|Please read the \"...|\n|eBook and Project...|\n|important informa...|\n|how the file may ...|\n|donation to Proje...|\n|                    |\n|                    |\n|**Welcome To The ...|\n+--------------------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.16.14.143:4040/jobs/job?id=45"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1533678870828_-1204880184",
      "id": "20180801-191033_464035631",
      "dateCreated": "2018-08-07 16:54:30.828",
      "dateStarted": "2018-08-07 19:51:22.998",
      "dateFinished": "2018-08-07 19:51:25.434",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n### Can you count the number of characters in the set of documents?",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:25.465",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Can you count the number of characters in the set of documents?</h3>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870829_883190487",
      "id": "20180730-125350_577688281",
      "dateCreated": "2018-08-07 16:54:30.829",
      "dateStarted": "2018-08-07 19:51:25.482",
      "dateFinished": "2018-08-07 19:51:25.484",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThis is exactly the same problem as the example the instructor demonstrated! There’s only a slight twist— rather than splitting the text into words, we need to split it into characters. Let's see how we can accomplish this by modifying the above functions:",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:25.584",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>This is exactly the same problem as the example the instructor demonstrated! There’s only a slight twist— rather than splitting the text into words, we need to split it into characters. Let&rsquo;s see how we can accomplish this by modifying the above functions:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870829_-1925691693",
      "id": "20180730-125420_2063509585",
      "dateCreated": "2018-08-07 16:54:30.829",
      "dateStarted": "2018-08-07 19:51:25.601",
      "dateFinished": "2018-08-07 19:51:25.603",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import scala.util.matching.Regex\n\ndef toChars(\n    documents: Dataset[String], \n    pattern: Regex = \".\".r) : Dataset[String] = \n{\n    documents\n        .flatMap(doc => doc.split(\"\"))\n        .map(char => char.toLowerCase)\n        .filter(char => pattern.findFirstIn(char) != None)\n}",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:25.701",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import scala.util.matching.Regex\ntoChars: (documents: org.apache.spark.sql.Dataset[String], pattern: scala.util.matching.Regex)org.apache.spark.sql.Dataset[String]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870830_-219786360",
      "id": "20180730-130712_353902806",
      "dateCreated": "2018-08-07 16:54:30.830",
      "dateStarted": "2018-08-07 19:51:25.717",
      "dateFinished": "2018-08-07 19:51:26.135",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNotice we added a `pattern` optional parameter that can come in handy if we want to restrict the characters that we analyze.",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:26.227",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Notice we added a <code>pattern</code> optional parameter that can come in handy if we want to restrict the characters that we analyze.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870830_-280341800",
      "id": "20180731-125435_1882541499",
      "dateCreated": "2018-08-07 16:54:30.830",
      "dateStarted": "2018-08-07 19:51:26.244",
      "dateFinished": "2018-08-07 19:51:26.247",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "def countChars(\n    documents: Dataset[String],\n    pattern: Regex = \".\".r) : Dataset[(String, Long)] = \n{\n    val chars = toChars(documents, pattern=pattern)\n    val counts = chars.groupByKey(identity).count()\n    counts\n}",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:26.346",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "countChars: (documents: org.apache.spark.sql.Dataset[String], pattern: scala.util.matching.Regex)org.apache.spark.sql.Dataset[(String, Long)]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870830_1465415028",
      "id": "20180730-131043_1715520435",
      "dateCreated": "2018-08-07 16:54:30.830",
      "dateStarted": "2018-08-07 19:51:26.377",
      "dateFinished": "2018-08-07 19:51:26.709",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nLet's give these functions a try:",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:26.784",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Let&rsquo;s give these functions a try:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870831_-1450679041",
      "id": "20180802-112502_1032268612",
      "dateCreated": "2018-08-07 16:54:30.831",
      "dateStarted": "2018-08-07 19:51:26.804",
      "dateFinished": "2018-08-07 19:51:26.807",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val chars = countChars(documents)\nchars.show()",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:26.904",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "chars: org.apache.spark.sql.Dataset[(String, Long)] = [value: string, count(1): bigint]\n+-----+--------+\n|value|count(1)|\n+-----+--------+\n|    7|    1890|\n|    ~|       2|\n|    l|  198648|\n|    ;|    3511|\n|    x|    9810|\n|    =|    1764|\n|    <|       2|\n|    ]|     435|\n|    g|   96916|\n|    3|    2492|\n|    8|    2527|\n|    +|      91|\n|    *|     489|\n|    0|    3064|\n|    m|  127063|\n|    !|    4345|\n|    \t|      12|\n|    f|  120875|\n|    5|    2192|\n|    (|    1748|\n+-----+--------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.16.14.143:4040/jobs/job?id=46",
            "http://172.16.14.143:4040/jobs/job?id=47",
            "http://172.16.14.143:4040/jobs/job?id=48",
            "http://172.16.14.143:4040/jobs/job?id=49"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1533678870831_-1894757322",
      "id": "20180731-125616_1021872024",
      "dateCreated": "2018-08-07 16:54:30.831",
      "dateStarted": "2018-08-07 19:51:26.921",
      "dateFinished": "2018-08-07 19:51:31.133",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nLet's see what happens if we pass a pattern to analyze only alphabetic characters:",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:31.234",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Let&rsquo;s see what happens if we pass a pattern to analyze only alphabetic characters:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870832_-1058674776",
      "id": "20180731-125548_884328081",
      "dateCreated": "2018-08-07 16:54:30.832",
      "dateStarted": "2018-08-07 19:51:31.250",
      "dateFinished": "2018-08-07 19:51:31.252",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val alphas = countChars(documents, \"[a-zA-Z]\".r)\nalphas.show()",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:31.351",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "alphas: org.apache.spark.sql.Dataset[(String, Long)] = [value: string, count(1): bigint]\n+-----+--------+\n|value|count(1)|\n+-----+--------+\n|    l|  198648|\n|    x|    9810|\n|    g|   96916|\n|    m|  127063|\n|    f|  120875|\n|    n|  369018|\n|    k|   32798|\n|    v|   52378|\n|    e|  633818|\n|    o|  386867|\n|    h|  294681|\n|    z|    3796|\n|    p|   98913|\n|    d|  215706|\n|    y|   90481|\n|    w|  100831|\n|    c|  144972|\n|    u|  138732|\n|    i|  365638|\n|    q|    4571|\n+-----+--------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.16.14.143:4040/jobs/job?id=50",
            "http://172.16.14.143:4040/jobs/job?id=51",
            "http://172.16.14.143:4040/jobs/job?id=52",
            "http://172.16.14.143:4040/jobs/job?id=53",
            "http://172.16.14.143:4040/jobs/job?id=54"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1533678870832_441474099",
      "id": "20180730-131159_962072403",
      "dateCreated": "2018-08-07 16:54:30.832",
      "dateStarted": "2018-08-07 19:51:31.367",
      "dateFinished": "2018-08-07 19:51:34.206",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Which are the top 10 longest words and how many of each are there in the dataset?",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:34.253",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Which are the top 10 longest words and how many of each are there in the dataset?</h3>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870833_1938572390",
      "id": "20180717-211705_1316930531",
      "dateCreated": "2018-08-07 16:54:30.833",
      "dateStarted": "2018-08-07 19:51:34.272",
      "dateFinished": "2018-08-07 19:51:34.275",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThe solution to this exercise is very simple if you followed the example during the session, because you already had all the information you needed: words and their counts. All that was missing was to learn how to sort that information by the length of each word. Here's a possible solution:",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:34.371",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>The solution to this exercise is very simple if you followed the example during the session, because you already had all the information you needed: words and their counts. All that was missing was to learn how to sort that information by the length of each word. Here&rsquo;s a possible solution:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870833_-272261100",
      "id": "20180717-211949_34443017",
      "dateCreated": "2018-08-07 16:54:30.833",
      "dateStarted": "2018-08-07 19:51:34.388",
      "dateFinished": "2018-08-07 19:51:34.392",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "def determineLongestWords(\n    documents: Dataset[String], \n    separatorsRegexp: String = \"\"\"\\s+\"\"\"): Dataset[(Int, String, Long)] = \n{\n    val words = countWords(documents, separatorsRegexp)\n    words.map { case (word, count) => (word.size, word, count) }\n         .orderBy($\"_1\".desc)\n}",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:34.489",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "determineLongestWords: (documents: org.apache.spark.sql.Dataset[String], separatorsRegexp: String)org.apache.spark.sql.Dataset[(Int, String, Long)]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870834_965039574",
      "id": "20180717-212002_1888821357",
      "dateCreated": "2018-08-07 16:54:30.834",
      "dateStarted": "2018-08-07 19:51:34.504",
      "dateFinished": "2018-08-07 19:51:35.166",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val punctuationRegexp = \"\"\"[\\p{Punct}\\s]\"\"\"\nval longest = determineLongestWords(documents, punctuationRegexp)\nlongest.show()",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:35.215",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "punctuationRegexp: String = [\\p{Punct}\\s]\nlongest: org.apache.spark.sql.Dataset[(Int, String, Long)] = [_1: int, _2: string ... 1 more field]\n+---+------------------+---+\n| _1|                _2| _3|\n+---+------------------+---+\n| 18|disproportionately|  2|\n| 18|supersensitiveness|  2|\n| 18|characteristically|  6|\n| 17| constitutionality|  6|\n| 17| contemporaneously|  1|\n| 17| indistinguishable|  2|\n| 17| unapproachability|  1|\n| 17| telecommunication|  1|\n| 17| disfranchisements|  1|\n| 17| disadvantageously|  1|\n| 17| superstitiousness|  1|\n| 17| misunderstandings|  6|\n| 17| conventionalities|  1|\n| 16|  enthusiastically|  3|\n| 16|  circumstantially|  1|\n| 16|  unenforceability|  2|\n| 16|  lymphangioplasty|  3|\n| 16|  superciliousness|  1|\n| 16|  incomprehensible| 41|\n| 16|  insurrectionists|  1|\n+---+------------------+---+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.16.14.143:4040/jobs/job?id=55"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1533678870834_1076873262",
      "id": "20180717-212100_4676898",
      "dateCreated": "2018-08-07 16:54:30.834",
      "dateStarted": "2018-08-07 19:51:35.234",
      "dateFinished": "2018-08-07 19:51:38.570",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nAs you can see, the solution is quite simple. Perhaps the only part that deserves an explanation is the line: `.orderBy($\"_1\".desc)`. The `$` is an operator that turns its operand (in this case `\"_1\"`) into an object of type `org.apache.spark.sql.Column`, and `\"_1\"` is just the default name that `Dataset`s give to fields when you use tuples rather than the `Row` object, as we are doing in this case.",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:59.928",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>As you can see, the solution is quite simple. Perhaps the only part that deserves an explanation is the line: <code>.orderBy($&quot;_1&quot;.desc)</code>. The <code>$</code> is an operator that turns its operand (in this case <code>&quot;_1&quot;</code>) into an object of type <code>org.apache.spark.sql.Column</code>, and <code>&quot;_1&quot;</code> is just the default name that <code>Dataset</code>s give to fields when you use tuples rather than the <code>Row</code> object, as we are doing in this case.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870834_-623075195",
      "id": "20180717-212123_154082817",
      "dateCreated": "2018-08-07 16:54:30.834",
      "dateStarted": "2018-08-07 19:51:59.929",
      "dateFinished": "2018-08-07 19:51:59.932",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n### Can you find all anagrams sets with at least two words?\n\nRemember that two words are anagrams of each other if they contain the same number of occurrences of each letter.\nFor example: `areAnagrams(\"mar\", “ram”) == true`, but `areAnagrams(\"line\", “nilee”) == false`\n\nConsider the following set of documents:\n\n`documents = [ “car art”, “rat arc” ]`\n\nIn this case, there are two such sets: `[“rat”, “art”]` and `[“car”, “arc”]` because they contain at least two elements. \n\nNow consider the following set of documents:\n\n`documents = [ “wizeline rocks”, “chuck norris” ]`\n\nIn this case, there are no such sets.",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:38.709",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Can you find all anagrams sets with at least two words?</h3>\n<p>Remember that two words are anagrams of each other if they contain the same number of occurrences of each letter.<br/>For example: <code>areAnagrams(&quot;mar&quot;, “ram”) == true</code>, but <code>areAnagrams(&quot;line&quot;, “nilee”) == false</code></p>\n<p>Consider the following set of documents:</p>\n<p><code>documents = [ “car art”, “rat arc” ]</code></p>\n<p>In this case, there are two such sets: <code>[“rat”, “art”]</code> and <code>[“car”, “arc”]</code> because they contain at least two elements. </p>\n<p>Now consider the following set of documents:</p>\n<p><code>documents = [ “wizeline rocks”, “chuck norris” ]</code></p>\n<p>In this case, there are no such sets.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870835_203231180",
      "id": "20180717-213338_1287781038",
      "dateCreated": "2018-08-07 16:54:30.835",
      "dateStarted": "2018-08-07 19:51:38.725",
      "dateFinished": "2018-08-07 19:51:38.729",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThis exercise is much more involved, as it requires to first think of a conceptual solution to find whether two words are anagrams of each other, and then to figure out which functions to use to achieve each intermediate step in the computation. Here's a possible solution:",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:38.828",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>This exercise is much more involved, as it requires to first think of a conceptual solution to find whether two words are anagrams of each other, and then to figure out which functions to use to achieve each intermediate step in the computation. Here&rsquo;s a possible solution:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870835_-1109502861",
      "id": "20180717-213513_1398409936",
      "dateCreated": "2018-08-07 16:54:30.835",
      "dateStarted": "2018-08-07 19:51:38.845",
      "dateFinished": "2018-08-07 19:51:38.848",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "def anagramSets(documents: Dataset[String], separatorsRegexp: String = \"\"\"\\s+\"\"\"): Dataset[List[String]] = {\n    val words = toWords(documents, separatorsRegexp).distinct()\n    val anagrams = words.groupByKey(word => word.sorted)\n      .mapGroups((word, anagrams) => anagrams.toList)\n      .filter(anagrams => anagrams.size > 1)\n\n    anagrams\n}",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:38.949",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "anagramSets: (documents: org.apache.spark.sql.Dataset[String], separatorsRegexp: String)org.apache.spark.sql.Dataset[List[String]]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870835_1899530953",
      "id": "20180717-213653_1753752118",
      "dateCreated": "2018-08-07 16:54:30.835",
      "dateStarted": "2018-08-07 19:51:38.964",
      "dateFinished": "2018-08-07 19:51:39.409",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val anagrams = anagramSets(documents, punctuationRegexp)\nanagrams.show()",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:39.475",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "anagrams: org.apache.spark.sql.Dataset[List[String]] = [value: array<string>]\n+--------------------+\n|               value|\n+--------------------+\n|            [07, 70]|\n|     [467, 647, 476]|\n|          [oka, oak]|\n|[art, rat, tar, tra]|\n|  [boredom, bedroom]|\n|[recourse, resource]|\n|    [corpus, croups]|\n|        [lids, slid]|\n|[125, 521, 512, 2...|\n|    [leaned, leaden]|\n|[please, elapse, ...|\n|[aet, eat, tea, ate]|\n|  [grieved, diverge]|\n|  [whoever, however]|\n|        [more, rome]|\n|          [map, amp]|\n|      [relic, crile]|\n|    [smiled, misled]|\n|          [der, red]|\n|      [slung, lungs]|\n+--------------------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.16.14.143:4040/jobs/job?id=56",
            "http://172.16.14.143:4040/jobs/job?id=57"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1533678870836_-1083081423",
      "id": "20180717-214241_1649052576",
      "dateCreated": "2018-08-07 16:54:30.836",
      "dateStarted": "2018-08-07 19:51:39.492",
      "dateFinished": "2018-08-07 19:51:48.807",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nLet's break it down line by line. The first line: `val words = toWords(documents, separatorsRegexp).distinct()` just gives you back a list of unique words. Simple enough!",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:48.896",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Let&rsquo;s break it down line by line. The first line: <code>val words = toWords(documents, separatorsRegexp).distinct()</code> just gives you back a list of unique words. Simple enough!</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870836_334107403",
      "id": "20180717-213748_1295804378",
      "dateCreated": "2018-08-07 16:54:30.836",
      "dateStarted": "2018-08-07 19:51:48.915",
      "dateFinished": "2018-08-07 19:51:48.918",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThe second line: `val anagrams = words.groupByKey(word => word.sorted)` groups words as anagrams by proposing a way to figure out whether two words are anagrams of each other— simply sort their characters and compare the resulting strings!",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:49.018",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>The second line: <code>val anagrams = words.groupByKey(word =&gt; word.sorted)</code> groups words as anagrams by proposing a way to figure out whether two words are anagrams of each other— simply sort their characters and compare the resulting strings!</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870836_-2042063084",
      "id": "20180717-213852_521170903",
      "dateCreated": "2018-08-07 16:54:30.836",
      "dateStarted": "2018-08-07 19:51:49.037",
      "dateFinished": "2018-08-07 19:51:49.041",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nIn the third line: `.mapGroups((word, anagrams) => anagrams.toList)` we discard the keys of the previous grouping, because we don't really need them anymore. All we care about is the list of values for each group, which happens to be an \"iterable\", hence the need to call `.toList`",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:49.137",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>In the third line: <code>.mapGroups((word, anagrams) =&gt; anagrams.toList)</code> we discard the keys of the previous grouping, because we don&rsquo;t really need them anymore. All we care about is the list of values for each group, which happens to be an &ldquo;iterable&rdquo;, hence the need to call <code>.toList</code></p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870836_-1018004652",
      "id": "20180717-213951_1951649187",
      "dateCreated": "2018-08-07 16:54:30.836",
      "dateStarted": "2018-08-07 19:51:49.157",
      "dateFinished": "2018-08-07 19:51:49.160",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nFinally, in the last line: `.filter(lambda anagrams: anagrams.size > 1)` we remove the trivial groups— those that contain just one element.",
      "user": "anonymous",
      "dateUpdated": "2018-08-07 19:51:49.259",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Finally, in the last line: <code>.filter(lambda anagrams: anagrams.size &gt; 1)</code> we remove the trivial groups— those that contain just one element.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1533678870837_577121373",
      "id": "20180717-214112_288924767",
      "dateCreated": "2018-08-07 16:54:30.837",
      "dateStarted": "2018-08-07 19:51:49.277",
      "dateFinished": "2018-08-07 19:51:49.279",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "wordcount-scala-exercises-solutions.json",
  "id": "2DKDC5D7D",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}